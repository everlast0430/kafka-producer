#-------------------------------- install_kafka.yml ------------------------------------
- name: install Confluent Kafka
  hosts: kafka #kafka broker server 대상
  tasks:
    - name: Add Kafka group
      ansible.builtin.group: #ansible이 가지고 있는 모듈중 group을 사용
        name: kafka # kafka group을 생성
        gid: 1001 # group ID
        system: false # 시스템 그룹은 false -> 일반그룹으로 생성
      become: yes # 수도권한으로 작업

    - name: Add Kafka user # user 모듈
      ansible.builtin.user:
        name: kafka # kafka user 생성
        shell: /bin/bash # login 셀은 /bin/bash 셀을 사용
        uid: 1001
        group: kafka
        groups: ubuntu # 추가적인 group은 ubuntu로 설정
        comment: User for Kafka Cluster
      become: yes

    - name: make directory
      ansible.builtin.file:
        path: /engine
        state: directory
      become: yes

    - name: unarchive file
      ansible.builtin.unarchive:
        src: /home/ec2-user/downloads/confluent-community-6.2.14.tar.gz
        dest: /engine
        copy: true
        owner: kafka
        group: kafka
      become: yes

    - name: make data directory
      ansible.builtin.file:
        path: /data
        state: directory
      become: yes

    - name: make data directory
      ansible.builtin.file:
        path: /src
        state: directory
      become: yes

    - name: create log directory
      become: yes
      file:
        path: /log
        owner: kafka
        group: kafka
        state: directory

    - name: make kafka segment directory
      ansible.builtin.file:
        path: /data/kafka-logs
        state: directory
        owner: kafka
        group: kafka
      become: yes

#-------------------------------- setting_hosts.yml ------------------------------------
- name: Setting /etc/hosts file
  hosts: kafka
  tasks:
    - name: setting kafka broker hosts
      blockinfile: # block의 내용을 한 번에 추가
        path: /etc/hosts
        block: | # 줄바꿈 기능
          172.31.27.133 kafka01
          172.31.32.153 kafka02
          172.31.48.244 kafka03
        marker: "# {mark} Setting datalake hosts"
      become: yes

    - name: setting hostname
      lineinfile: # 특정 내용을 찾아서 변경하는 모듈
        path: /etc/hostname
        regexp: '^(ip|kafka)'
        line: '{{ inventory_hostname }}' # kafka01 ~ kafka03
      become: yes

    - name: change timezone
      command: # command 모듈을 이용한 한국시간 설정
        cmd: timedatectl set-timezone Asia/Seoul
      become: yes

#-------------------------------- setting_hosts.yml ------------------------------------
- name: create python env # ansible playbook 이름
  hosts: kafka # kafka 서버들에서 실행
  tasks: # 아래에 있는 작업들을 순서대로 진행
    - name: install pkg for add repository #
      become: yes # 관리자 권한으로 시작
      apt:
        pkg: # 설치할 패키지
          - software-properties-common # 아래 저장소를 설치하기전 설치할 패키지
        update_cache: true

    - name: Add repo
      become: yes
      apt_repository:
        repo: ppa:deadsnakes/ppa # python 3.10을 설치하기위한 비공식 레파지토리 # 우분투 공식 레파지토리에는 python 3.10이 없음
        # sudo add-apt-repository ppa:deadsnakes/ppa

    - name: install python3.10, python3-pip, venv
      become: true
      apt:
        pkg:
          - python3.10
          - python3-pip
          - python3.10-venv
        update_cache: true

    - name: create python virtual environment # 가상환경 설치
      become: true
      command:
        cmd: python3.10 -m venv /src/kafka_venv
        creates: /src/kafka_venv

    - name: change owner to kafka
      become: true
      file:
        path: /src/kafka_venv
        owner: kafka
        group: kafka
        recurse: yes

    - name: Modify .bashrc #  가상환경 진입/ 환경변수에 경로하나 추가
      blockinfile:
        path: /home/kafka/.bashrc
        block: |
          source /src/kafka_venv/bin/activate  
          export PYTHONPATH="${PYTHONPATH}:/src/kafka-producer" 
          alias src="cd /src"
          alias bin="cd /engine/confluent-6.2.14/bin"
          alias logs="cd /engine/confluent-6.2.14/logs"
        marker: "# {mark} Setting bashrc"
      become: yes

#-------------------------------- install_zookeeper.yml ------------------------------------

    - name: install Zookeeper
      hosts: kafka
      tasks:
        - name: Add Zookeeper group
          ansible.builtin.group: # zookeeper group 생성
            name: zookeeper
            gid: 1002 # group ID 1002로 설정
            system: false
          become: yes

    - name: Add Zookeeper user
      ansible.builtin.user: # zookeeper user 생성
        name: zookeeper
        shell: /bin/bash
        uid: 1002
        group: zookeeper
        comment: User for Zookeeper
      become: yes

    - name: make directory
      ansible.builtin.file:
        path: /engine
        state: directory
      become: yes

    - name: unarchive file
      ansible.builtin.unarchive: # 압축파일 풀기
        src: /home/ec2-user/downloads/apache-zookeeper-3.8.4-bin.tar.gz
        dest: /engine
        copy: true
        owner: zookeeper
        group: zookeeper
      become: yes

    - name: Install Java 17
      ansible:builtin.apt:
        name: openjdk-17-jre
        update_cache: true
      become: yes

#-------------------------------- setting_zookeeper.yml ------------------------------------
    - name: Setting Zookeeper Service
      hosts: kafka
      tasks:
        - name: Copy zoo_sample.cfg to zoo.cfg
          copy:
            src: /engine/apache-zookeeper-3.8.4-bin/conf/zoo_sample.cfg
            dest: /engine/apache-zookeeper-3.8.4-bin/conf/zoo.cfg
            remote_src: yes # nat서버가 아니라 kafka 서버의 디렉토리에 직접 복사
            owner: zookeeper
            group: zookeeper
          become: yes

        - name: Create zookeeper data directory
          file:
            path: /data/zookeeper
            owner: zookeeper
            group: zookeeper
            state: directory # data/zookeeper 디렉토리 생성
          become: yes

        - name: create myid file # zookeeper 노드마다 고유한 myid 파일이 있어야 함
          lineinfile: # myid에 있는 어떤 데이터를 치환해주겠음
            path: /data/zookeeper/myid # 주키퍼 노드마다 고유한 숫자값이 있음
            create: yes
            state: present
            owner: zookeeper
            group: zookeeper
            regex: '^[0-9]' # 0~9의 값이 있을경우 kafka_broker_no 이 값으로 치환
            line: '{{ kafka_broker_no }}' #
          become: yes

        - name: setting zoo.cfg
          lineinfile:
            path: /engine/apache-zookeeper-3.8.4-bin/conf/zoo.cfg
            regex: '{{ item.group }}'
            line: '{{ item.line }}'
          loop:
            - { regexp: '^dataDir', line: 'dataDir=/data/zookeeper' }
            - { regexp: '^server1', line: 'server.1=kafka01:2888:3888' }
            - { regexp: '^server2', line: 'server.2=kafka02:2888:3888' }
            - { regexp: '^server3', line: 'server.3=kafka03:2888:3888' }
          become: yes

#-------------------------------- start_zookeeper-service.yml ------------------------------------

---
- name: Register Zookeeper service as a daemon
  hosts: kafka
  tasks:
    - name: zookeeper.service file
      blockinfile:
        path: /etc/systemd/system/zookeeper.service
        create: yes
        block: |
          [Unit]
          Description=Zookeeper Service
          After=network.target
          
          [Service]
          Type=forking
          ExecStart=/engine/apache-zookeeper-3.8.4-bin/bin/zkServer.sh start
          ExecStop=/engine/apache-zookeeper-3.8.4-bin/bin/zkServer.sh stop
          ExecReload=/engine/apache-zookeeper-3.8.4-bin/bin/zkServer.sh restart
          User=zookeeper
          Group=zookeeper
          Restart=always
          
          [Install]
          WantedBy=multi-user.target
        marker: "# {mark} Zookeeper Service"
      become: yes
    - name: daemon-reload
      systemd_service:
        daemon_reload: yes
      become: yes
    - name: Start Zookeeper Service
      systemd_service:
        state: started
        name: zookeeper
        enabled: true
      become: yes
      tags:
        - start

#-------------------------------- start_kafka-service.yml ------------------------------------

- name: Register kafka service as a daemon
  hosts: kafka
  tasks:
    - name: kafka.service file
      blockinfile:
        path: /etc/systemd/system/kafka.service
        create: yes
        block: |
          [Unit]
          Description=kafka Service
          After=network.target zookeeper.service
          
          [Service]
          Type=simple
          WorkingDirectory=/engine/confluent-6.2.14
          ExecStart=/engine/confluent-6.2.14/bin/kafka-server-start /engine/confluent-6.2.14/etc/kafka/server.properties
          ExecStop=/engine/confluent-6.2.14/bin/kafka-server-stop
          User=kafka
          Group=kafka
          Restart=always
          
          [Install]
          WantedBy=multi-user.target
        marker: "# {mark} Kafka Service"
      become: yes
    - name: daemon-reload
      systemd_service:
        daemon_reload: true
    - name: Start kafka service
      systemd_service:
        state: started
        name: kafka
        enabled: true

#-------------------------------- setting_kafka-broker.yml ------------------------------------

    - name: Setting Kafka Broker
      hosts: kafka
      tasks:
        - name: setting kafka server.properties
          lineinfile:
            path: /engine/confluent-6.2.14/etc/kafka/server.properties
            regexp: '{{ item.regexp }}'
            line: '{{ item.line }}'
          loop:
            - { regexp: '^broker\.id', line: 'broker.id={{ kafka_broker_no }}'} # 몇 번쨰 프로커인지
            - { regexp: '^log\.dirs', line: 'log.dirs=/data/kafka-logs' } # 어디에 로그를 저장할지
            - { regexp: '^zookeeper\.connect', line: 'zookeeper.connect=kafka01:2181,kafka02:2181,kafka03:21881' } # 어떤 주키퍼를 연결할 것인지
            - { regexp: '^default\.replication\.factor', line: 'default.replication.factor=3'} # 복제 기본값
            - { regexp: '^[#]*advertised\.listeners', line: 'advertised.listeners=PLAINTEXT://{{ inventory_hostname }}:9092'}
            # consumer/producer 와 같은 client가 접근할 떄 보여줄 주소
          become: yes

#-------------------------------- register_producer_as_daemon.yml ------------------------------------